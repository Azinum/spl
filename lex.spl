// lex.spl

// enum Token_type {
const T_EOF 0;

const T_IDENTIFIER 1;
const T_NUMBER 2;
const T_CSTRING 3;
const T_ASSIGN 4;
const T_COMMA 5;
const T_AT 6;
const T_DEREF 7;
const T_ADD 8;
const T_SUB 9;
const T_MUL 10;
const T_DIV 11;
const T_DIVMOD 12;
const T_LSHIFT 13;
const T_RSHIFT 14;
const T_LT 15;
const T_GT 16;
const T_AND 17;
const T_LOGICAL_NOT 18;
const T_OR 19;
const T_EQ 20;
const T_NEQ 21;
const T_SEMICOLON 22;
const T_POP 23;
const T_CONST 24;
const T_LET 25;
const T_MEMORY 26;
const T_PRINT 27;
const T_INCLUDE 28;
const T_FN 29;
const T_ARROW 30;
const T_WHILE 31;
const T_IF 32;
const T_ELSE 33;
const T_LEFT_P 34;
const T_RIGHT_P 35;
const T_LEFT_BRACKET 36;
const T_RIGHT_BRACKET 37;
const T_LEFT_CURLY 38;
const T_RIGHT_CURLY 39;
const T_STORE64 40;
const T_STORE32 41;
const T_STORE16 42;
const T_STORE8 43;
const T_LOAD64 44;
const T_LOAD32 45;
const T_LOAD16 46;
const T_LOAD8 47;
const T_SIZEOF 48;

// built-in types
const T_NONE 49;
const T_ANY 50;
const T_UNSIGNED64 51;
const T_CSTR 52;

const MAX_TOKEN_TYPE 53;
// };

let token_type_str "";

let token.buffer 0;
let token.length 0;
let token.type 0;
let token.value 0;
let token.filename "";
let token.source "";
let token.line 0;
let token.column 0;
let Token.size +++++++
  sizeof token.buffer
  sizeof token.length
  sizeof token.type
  sizeof token.value
  sizeof token.filename
  sizeof token.source
  sizeof token.line
  sizeof token.column;

memory token Token.size;

// struct Lexer {
let l.filename "";
let l.source "";
let l.index 0;
let l.line 0;
let l.column 0;
let l.status 0;
// };

fn token_init(any token, any buffer, u64 length, u64 type, any filename, any source) -> none {
  = token buffer;   = @token + sizeof token.buffer token;
  = token length;   = @token + sizeof token.length token;
  = token type;     = @token + sizeof token.type token;
  = token 0;        = @token + sizeof token.value token;
  = token filename; = @token + sizeof token.filename token;
  = token source;   = @token + sizeof token.source token;
  = token 1;        = @token + sizeof token.line token;
  = token 1;        = @token + sizeof token.column token;
}

fn token_print(any token) -> none {
  let tmp tmp_it;
  let p tmp_push_cstr;
  // oh boy, i really REALLY need proper structs
  let buffer #token;   = @token + sizeof token.buffer token;
  let length #token;   = @token + sizeof token.length token;
  let type #token;     = @token + sizeof token.type token;
  let value #token;    = @token + sizeof token.value token;
  let filename #token; = @token + sizeof token.filename token;
  let source #token;   = @token + sizeof token.source token;
  let line #token;     = @token + sizeof token.line token;
  let column #token;   = @token + sizeof token.column token;

  if eq filename 0 = @filename "none";

  p("buffer   = "); tmp_push_str(buffer, length);
  p("\n");
  p("length   = "); tmp_push_u64(length);
  p("\n");
  p("type     = "); tmp_push_u64(type);
  p("\n");
  p("filename = "); p(filename);
  p("\n");
  p("line     = "); tmp_push_u64(line);
  p("\n");
  p("column   = "); tmp_push_u64(column);
  p("\n");

  puts(1, tmp);
  = @tmp_it tmp;
}

fn lexer_init(any filename, any source) -> none {
  = @l.filename filename;
  = @l.source source;
  = @l.index source;
  = @l.index 1;
  = @l.column 1;
  = @l.status NoError;
  let t (
    "T_EOF",

    "T_IDENTIFIER",
    "T_NUMBER",
    "T_CSTRING",
    "T_ASSIGN",
    "T_COMMA",
    "T_AT",
    "T_DEREF",
    "T_ADD",
    "T_SUB",
    "T_MUL",
    "T_DIV",
    "T_DIVMOD",
    "T_LSHIFT",
    "T_RSHIFT",
    "T_LT",
    "T_GT",
    "T_AND",
    "T_LOGICAL_NOT",
    "T_OR",
    "T_EQ",
    "T_NEQ",
    "T_SEMICOLON",
    "T_POP",
    "T_CONST",
    "T_LET",
    "T_MEMORY",
    "T_PRINT",
    "T_INCLUDE",
    "T_FN",
    "T_ARROW",
    "T_WHILE",
    "T_IF",
    "T_ELSE",
    "T_LEFT_P",
    "T_RIGHT_P",
    "T_LEFT_BRACKET",
    "T_RIGHT_BRACKET",
    "T_LEFT_CURLY",
    "T_RIGHT_CURLY",
    "T_STORE64",
    "T_STORE32",
    "T_STORE16",
    "T_STORE8",
    "T_LOAD64",
    "T_LOAD32",
    "T_LOAD16",
    "T_LOAD8",
    "T_SIZEOF",

    "T_NONE",
    "T_ANY",
    "T_UNSIGNED64",
    "T_CSTR"
  );
  = @token_type_str @t;
  assert(eq (* sizeof any MAX_TOKEN_TYPE) (sizeof t), "mismatch between token_type_str and MAX_TOKEN_TYPE\n");

  token_init(@token, "test", 4, T_IDENTIFIER, filename, source);
  token_print(@token);
}
